[
  {
    "objectID": "posts/Valor de PI/index.html",
    "href": "posts/Valor de PI/index.html",
    "title": "Estimando el valor de Pi con puntitos",
    "section": "",
    "text": "Todos sabemos que el valor de \\(\\pi\\) es aproximadamente \\(3.1415...\\) y tal vez la “demostración” nos la enseñaron en la secundaria o preparatoria. Pero ¿y si lo vemos de otra manera? A continuación veremos otra forma de obtener el valor de \\(\\pi\\) pero con una herramienta muy poderosa llamada Simulación de Montecarlo.\n\n\nLa simulación de Montecarlo es un tipo de algoritmo computacional que utiliza un muestreo aleatorio repetido para obtener la probabilidad de que ocurra una serie de resultados.\nFue inventado por John von Neumann y Stanislaw Ulam durante la Segunda Guerra Mundial. Debe su nombre al famoso casino de Mónaco, ya que el elemento de azar es fundamental en el planteamiento del modelo, similar a un juego de ruleta. A diferencia de un modelo de pronóstico normal, esta simulación construye un modelo de posibles resultados aprovechando una distribución de probabilidad para cualquier variable que tenga incertidumbre inherente.\n\n\n\nSabemos por las fórmulas que nos enseñaron en la primaria que las áreas del cuadrado y del círculo se calculan como sigue:\n\\[\\text{Área del círculo} = \\pi \\cdot r^2\\] \\[\\text{Área del cuadrado} = l^2\\]\nSi inscribimos un círculo de radio \\(r=1\\) dentro de un cuadrado de lado \\(l=2\\), la relación de sus áreas es:\n\\[\\frac{\\text{Área del Círculo}}{\\text{Área del Cuadrado}} = \\frac{\\pi \\cdot 1^2}{2^2} = \\frac{\\pi}{4}\\]\nPor lo tanto, si lanzamos miles de puntos aleatorios al cuadrado, la proporción que caiga dentro del círculo multiplicada por 4 nos dará el valor de \\(\\pi\\).\n\n\n\nHaremos uso de numpy y matplotlib para mostrar gráficamente lo que sucede.\n\n\nVer código\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Funcion de la simulación \ndef ejecutar_simulacion(n):\n\n    puntos = np.random.uniform(-1, 1, (n, 2))\n    \n    distancias = np.sum(puntos**2, axis=1)\n    \n    dentro_circulo = distancias &lt;= 1\n    puntos_dentro = np.sum(dentro_circulo)\n    \n    pi_estimado = 4 * puntos_dentro / n\n    return puntos, dentro_circulo, pi_estimado\n\n# Ejecución\nn_puntos = 10000\npuntos, mascara, resultado = ejecutar_simulacion(n_puntos)\n\n# Graficar resultados\nplt.figure(figsize=(8, 8))\nplt.scatter(puntos[mascara, 0], puntos[mascara, 1], color='#2ecc71', s=1, label='Dentro')\nplt.scatter(puntos[~mascara, 0], puntos[~mascara, 1], color='#e74c3c', s=1, label='Fuera')\n\n# Dibujar el círculo teórico para referencia\ncirculo = plt.Circle((0, 0), 1, color='black', fill=False, linewidth=2)\nplt.gca().add_artist(circulo)\n\nplt.title(f\"Estimación de $\\pi$ con {n_puntos} puntos: {resultado:.4f}\")\nplt.axis('equal')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: Simulación de Montecarlo: Puntos verdes dentro del círculo vs rojos fuera.\n\n\n\n\n\n\n\n\nEl algoritmo funciona porque estamos simulando un experimento físico de manera digital. Al calcular np.sum(puntos**2, axis=1), estamos aplicando el teorema de Pitágoras para saber qué tan lejos está cada punto del centro \\((0,0)\\). Si la distancia es menor o igual a 1, el punto “golpeó” el círculo. A medida que aumentas el valor de \\(n\\) en el código, notarás que el valor estimado se acerca cada vez más al valor real de \\(3.14159...\\)\n\n\n\nLa simulación de Montecarlo nos enseña que el azar, cuando se repite masivamente, revela patrones matemáticos exactos. Esta técnica no solo sirve para calcular \\(\\pi\\), sino que es fundamental hoy en día en física nuclear, finanzas y ciencia de datos."
  },
  {
    "objectID": "posts/Valor de PI/index.html#el-valor-de-pi",
    "href": "posts/Valor de PI/index.html#el-valor-de-pi",
    "title": "Estimando el valor de Pi con puntitos",
    "section": "",
    "text": "Todos sabemos que el valor de \\(\\pi\\) es aproximadamente \\(3.1415...\\) y tal vez la “demostración” nos la enseñaron en la secundaria o preparatoria. Pero ¿y si lo vemos de otra manera? A continuación veremos otra forma de obtener el valor de \\(\\pi\\) pero con una herramienta muy poderosa llamada Simulación de Montecarlo.\n\n\nLa simulación de Montecarlo es un tipo de algoritmo computacional que utiliza un muestreo aleatorio repetido para obtener la probabilidad de que ocurra una serie de resultados.\nFue inventado por John von Neumann y Stanislaw Ulam durante la Segunda Guerra Mundial. Debe su nombre al famoso casino de Mónaco, ya que el elemento de azar es fundamental en el planteamiento del modelo, similar a un juego de ruleta. A diferencia de un modelo de pronóstico normal, esta simulación construye un modelo de posibles resultados aprovechando una distribución de probabilidad para cualquier variable que tenga incertidumbre inherente.\n\n\n\nSabemos por las fórmulas que nos enseñaron en la primaria que las áreas del cuadrado y del círculo se calculan como sigue:\n\\[\\text{Área del círculo} = \\pi \\cdot r^2\\] \\[\\text{Área del cuadrado} = l^2\\]\nSi inscribimos un círculo de radio \\(r=1\\) dentro de un cuadrado de lado \\(l=2\\), la relación de sus áreas es:\n\\[\\frac{\\text{Área del Círculo}}{\\text{Área del Cuadrado}} = \\frac{\\pi \\cdot 1^2}{2^2} = \\frac{\\pi}{4}\\]\nPor lo tanto, si lanzamos miles de puntos aleatorios al cuadrado, la proporción que caiga dentro del círculo multiplicada por 4 nos dará el valor de \\(\\pi\\).\n\n\n\nHaremos uso de numpy y matplotlib para mostrar gráficamente lo que sucede.\n\n\nVer código\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Funcion de la simulación \ndef ejecutar_simulacion(n):\n\n    puntos = np.random.uniform(-1, 1, (n, 2))\n    \n    distancias = np.sum(puntos**2, axis=1)\n    \n    dentro_circulo = distancias &lt;= 1\n    puntos_dentro = np.sum(dentro_circulo)\n    \n    pi_estimado = 4 * puntos_dentro / n\n    return puntos, dentro_circulo, pi_estimado\n\n# Ejecución\nn_puntos = 10000\npuntos, mascara, resultado = ejecutar_simulacion(n_puntos)\n\n# Graficar resultados\nplt.figure(figsize=(8, 8))\nplt.scatter(puntos[mascara, 0], puntos[mascara, 1], color='#2ecc71', s=1, label='Dentro')\nplt.scatter(puntos[~mascara, 0], puntos[~mascara, 1], color='#e74c3c', s=1, label='Fuera')\n\n# Dibujar el círculo teórico para referencia\ncirculo = plt.Circle((0, 0), 1, color='black', fill=False, linewidth=2)\nplt.gca().add_artist(circulo)\n\nplt.title(f\"Estimación de $\\pi$ con {n_puntos} puntos: {resultado:.4f}\")\nplt.axis('equal')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: Simulación de Montecarlo: Puntos verdes dentro del círculo vs rojos fuera.\n\n\n\n\n\n\n\n\nEl algoritmo funciona porque estamos simulando un experimento físico de manera digital. Al calcular np.sum(puntos**2, axis=1), estamos aplicando el teorema de Pitágoras para saber qué tan lejos está cada punto del centro \\((0,0)\\). Si la distancia es menor o igual a 1, el punto “golpeó” el círculo. A medida que aumentas el valor de \\(n\\) en el código, notarás que el valor estimado se acerca cada vez más al valor real de \\(3.14159...\\)\n\n\n\nLa simulación de Montecarlo nos enseña que el azar, cuando se repite masivamente, revela patrones matemáticos exactos. Esta técnica no solo sirve para calcular \\(\\pi\\), sino que es fundamental hoy en día en física nuclear, finanzas y ciencia de datos."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog:\nEste blog fue creado como un proyecto de pasatiempo en donde se busca mostrar algunas de las cosas aprendidas durante la carrera de Ingenieria Matematica, asi como las habilidades adquiridas posteriormente a la misma carrera.\n\n\nAbout me:\nMi nombre es Mauricio Leon, soy graduado de la Ingenieria en Matematicas de la Escuela Superior de Fisica y Matematicas (ESFM) del Insituto Politecnico Nacional (IPN). Me gusta estar aprendiendo constantemente y probarme a mi mismo con nuevos retos"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MaviBlog",
    "section": "",
    "text": "Dos chicas, un juego de billar y probabilidad\n\n\n\nprobabilidad\n\npython\n\nsimulación\n\n\n\n\n\n\n\n\n\nJan 20, 2026\n\n\nMauricio Leon\n\n\n\n\n\n\n\n\n\n\n\n\nEstimando el valor de Pi con puntitos\n\n\n\ngeometría\n\npython\n\nsimulación\n\n\n\n\n\n\n\n\n\nJan 20, 2026\n\n\nMauricio Leon\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Bayesian Billiards/index.html",
    "href": "posts/Bayesian Billiards/index.html",
    "title": "Dos chicas, un juego de billar y probabilidad",
    "section": "",
    "text": "En muchos juegos por puntos, como el billar o el tenis de mesa, surge de manera natural la pregunta: dado el marcador actual, ¿qué probabilidad tiene cada jugador de ganar el partido? Si conociéramos exactamente la habilidad de cada jugador, el problema sería sencillo de resolver con probabilidad elemental. Sin embargo, en la práctica esa habilidad es desconocida y solo podemos inferirla a partir de los puntos ya jugados.\nEste planteamiento da lugar al llamado Bayesian Billiards Problem, un ejemplo clásico que ilustra la diferencia entre el enfoque frecuentista y el bayesiano en estadística. En el escenario que estudiaremos, dos jugadoras A y B compiten por puntos independientes en una mesa de billar, en donde se lanza una bola de manera aleatoria la cual separa el lado de A (izquierdo) y el lado de la jugadora B (lado derecho), gana quien llega primero a 6, y el marcador actual es 5–3 a favor de A. A partir de este resultado parcial, queremos estimar la probabilidad de que B logre remontar y gane el partido.\nDesde el punto de vista frecuentista, se suele estimar la probabilidad de que A gane un punto usando la frecuencia observada (5 de 8), y con ese valor se calcula la probabilidad de que B gane tres puntos consecutivos. En contraste, el enfoque bayesiano modela la habilidad de A como un parámetro desconocido con una distribución previa, que se actualiza con los datos observados para obtener una distribución posterior, y a partir de ella se promedia la probabilidad de que B gane el partido.\n\n\nPrimero, tenemos el enfoque frecuentista, por lo que, partiendo de la información obtenida, sabemos que A tiene 5 puntos, B tiene 3 puntos y por ende, se han realizado 8 jugadas. Aquí se asume que la probabilidad de que A gane un punto es un parámetro fijo \\(p\\), y se estima con lo observado: \\[p = \\dfrac{5}{8} \\rightarrow q = 1-p = \\dfrac{3}{8}\\]\nComo la unica manera de que B gane es que realice 3 puntos seguidos tenemos que la probabilidad de que ocurra esto es: \\[P(\\text{B gane}) = \\left(\\dfrac{3}{8} \\right)^3 = \\dfrac{27}{512} \\approx 0.0527\\]\nes decir, tenemos una probabilidad de \\(5.27%\\) de que la jugadora B gane este juego.\n\n\n\nSin embargo, para el enfoque bayesiano, esto no es correcto, pues el valor de \\(p\\) ahora ya no es fijo, sino que se le da el tratamiento de una variable aleatoria en donde tenemos que: \\[\\bullet p \\sim Beta(1,1) \\text{y uniforme}\\] \\[\\bullet A \\text{ya ganó 5 y }B \\text{ya ganó 3}\\]\nPor lo que ahora tenemos: \\[p | datos \\sim Beta(1+5,1+3) = Beta(6,4)\\]\nDe aqui tenemos que la probabilidad gane este juego es: \\[P(B \\text{gana} | p) = (1-p)^3\\]\nLa probabilidad bayesiana es el promedio posterior: \\[P(B \\text{gana} | datos) = E[(1-p)^3]\\]\nPero como ya sabemos que \\(p \\sim Beta(6,4)\\), entonces \\[E[(1-p)^3] = \\dfrac{4\\cdot 5 \\cdot 6}{10\\cdot 11 \\cdot 12}=\\dfrac{1}{11}\\approx 0.0909\\]\nEs decir, que desde el enfoque bayesiano tenemos una probabilidad de que B gane del \\(9.09%\\), es decir, casi el doble del enfoque frecuentista. Pero ¿Como sabremos quien tiene la razón? Para esto, haremós uso de la Simulación de Montecarlo y responder esta pregunta.\n\n\n\nLa idea es muy sencilla (al igual que el codigo): Vamos a tirar la bola de manera al azar en una mesa de billar, que, por comodidad tendrá una longitud de 1 y dependiendo donde caiga, ese será nuestro punto de separador, es decir, que una vez tengamos nuestra separación en la mesa, se vuelve a tirar la bola para saber si cae del lado izquierdo (lado de la jugadora A) o el lado derecho (de la jugadora B).\nSi durante 8 jugadas llegamos al escenario inicial, es decir, que la jugadora A ha acumulado 5 puntos y B 3 puntos, entonces, podemos continuar con el juego para ver quien es el vencedor, realizando este mismo juego una cantidad n, donde n es un numero considerablemente grande (recordar que entre más grande, mejor)\nPor último, contamos cuantas de esas partidas ideales (5-3), B salio victoriosa.\nEl codigó de python es el siguiente:\n\n\nVer código\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ncontador = 0\nn = 10_000\ni = 0\n\nwhile i &lt; n:\n\n    separador = np.random.random()\n\n    bolas = np.random.random(8)\n    jugador_A = np.sum(bolas &lt; separador)\n    jugador_B = np.sum(bolas &gt;= separador)\n\n    if jugador_A == 5 and jugador_B == 3:\n        i += 1\n\n        while jugador_A &lt; 6 and jugador_B &lt; 6:\n            bola = np.random.random()\n            if bola &lt; separador:\n                jugador_A += 1\n            else:\n                jugador_B += 1\n\n        if jugador_B == 6:\n            contador += 1\n\nplt.figure(figsize=(8, 4))\nax = plt.gca()\nax.set_facecolor(\"#3a7352\")\ny = np.random.random(8)\nplt.scatter(bolas[bolas &lt; separador], y[:5], color='#2ecc71', s=100, label='Puntos para A')\nplt.scatter(bolas[bolas &gt;= separador], y[5:], color='#e74c3c', s=100, label='Puntos para B')\nplt.axvline(x=separador, color='black', linestyle='--', linewidth=2)\nplt.xlim([0,1])\nplt.ylim([0,1])\nplt.legend()\nplt.title(f\"Partida al inicio del problema (puntos dados al azar)\")\nplt.show()\n\nprint(f\"Numero de partidas: {n}\")\nprint(f\"Numero de veces que gana A: {n-contador}\")\nprint(f\"Numero de veces que gana B: {contador}\")\nprint(f\"Probabilidad de que B gane: {contador/n}\")\n\n\n\n\n\n\n\n\n\nNumero de partidas: 10000\nNumero de veces que gana A: 9098\nNumero de veces que gana B: 902\nProbabilidad de que B gane: 0.0902\n\n\n\n\n\nComo se puede observar, el resultado es el mismo que lo que plantea la estadistica bayesiana (o al menos se acerca mucho), por lo que, una vez la simulacion de montecarlo nos enseña como muchas veces no necesitamos formulas que pueden resultar complicadas o tediosas de entender, sino entender realmente el problema y con un par de lineas de codigo resolver este tipo de incognitas."
  },
  {
    "objectID": "posts/Bayesian Billiards/index.html#el-problema-de-puzzle-del-billar",
    "href": "posts/Bayesian Billiards/index.html#el-problema-de-puzzle-del-billar",
    "title": "Dos chicas, un juego de billar y probabilidad",
    "section": "",
    "text": "En muchos juegos por puntos, como el billar o el tenis de mesa, surge de manera natural la pregunta: dado el marcador actual, ¿qué probabilidad tiene cada jugador de ganar el partido? Si conociéramos exactamente la habilidad de cada jugador, el problema sería sencillo de resolver con probabilidad elemental. Sin embargo, en la práctica esa habilidad es desconocida y solo podemos inferirla a partir de los puntos ya jugados.\nEste planteamiento da lugar al llamado Bayesian Billiards Problem, un ejemplo clásico que ilustra la diferencia entre el enfoque frecuentista y el bayesiano en estadística. En el escenario que estudiaremos, dos jugadoras A y B compiten por puntos independientes en una mesa de billar, en donde se lanza una bola de manera aleatoria la cual separa el lado de A (izquierdo) y el lado de la jugadora B (lado derecho), gana quien llega primero a 6, y el marcador actual es 5–3 a favor de A. A partir de este resultado parcial, queremos estimar la probabilidad de que B logre remontar y gane el partido.\nDesde el punto de vista frecuentista, se suele estimar la probabilidad de que A gane un punto usando la frecuencia observada (5 de 8), y con ese valor se calcula la probabilidad de que B gane tres puntos consecutivos. En contraste, el enfoque bayesiano modela la habilidad de A como un parámetro desconocido con una distribución previa, que se actualiza con los datos observados para obtener una distribución posterior, y a partir de ella se promedia la probabilidad de que B gane el partido.\n\n\nPrimero, tenemos el enfoque frecuentista, por lo que, partiendo de la información obtenida, sabemos que A tiene 5 puntos, B tiene 3 puntos y por ende, se han realizado 8 jugadas. Aquí se asume que la probabilidad de que A gane un punto es un parámetro fijo \\(p\\), y se estima con lo observado: \\[p = \\dfrac{5}{8} \\rightarrow q = 1-p = \\dfrac{3}{8}\\]\nComo la unica manera de que B gane es que realice 3 puntos seguidos tenemos que la probabilidad de que ocurra esto es: \\[P(\\text{B gane}) = \\left(\\dfrac{3}{8} \\right)^3 = \\dfrac{27}{512} \\approx 0.0527\\]\nes decir, tenemos una probabilidad de \\(5.27%\\) de que la jugadora B gane este juego.\n\n\n\nSin embargo, para el enfoque bayesiano, esto no es correcto, pues el valor de \\(p\\) ahora ya no es fijo, sino que se le da el tratamiento de una variable aleatoria en donde tenemos que: \\[\\bullet p \\sim Beta(1,1) \\text{y uniforme}\\] \\[\\bullet A \\text{ya ganó 5 y }B \\text{ya ganó 3}\\]\nPor lo que ahora tenemos: \\[p | datos \\sim Beta(1+5,1+3) = Beta(6,4)\\]\nDe aqui tenemos que la probabilidad gane este juego es: \\[P(B \\text{gana} | p) = (1-p)^3\\]\nLa probabilidad bayesiana es el promedio posterior: \\[P(B \\text{gana} | datos) = E[(1-p)^3]\\]\nPero como ya sabemos que \\(p \\sim Beta(6,4)\\), entonces \\[E[(1-p)^3] = \\dfrac{4\\cdot 5 \\cdot 6}{10\\cdot 11 \\cdot 12}=\\dfrac{1}{11}\\approx 0.0909\\]\nEs decir, que desde el enfoque bayesiano tenemos una probabilidad de que B gane del \\(9.09%\\), es decir, casi el doble del enfoque frecuentista. Pero ¿Como sabremos quien tiene la razón? Para esto, haremós uso de la Simulación de Montecarlo y responder esta pregunta.\n\n\n\nLa idea es muy sencilla (al igual que el codigo): Vamos a tirar la bola de manera al azar en una mesa de billar, que, por comodidad tendrá una longitud de 1 y dependiendo donde caiga, ese será nuestro punto de separador, es decir, que una vez tengamos nuestra separación en la mesa, se vuelve a tirar la bola para saber si cae del lado izquierdo (lado de la jugadora A) o el lado derecho (de la jugadora B).\nSi durante 8 jugadas llegamos al escenario inicial, es decir, que la jugadora A ha acumulado 5 puntos y B 3 puntos, entonces, podemos continuar con el juego para ver quien es el vencedor, realizando este mismo juego una cantidad n, donde n es un numero considerablemente grande (recordar que entre más grande, mejor)\nPor último, contamos cuantas de esas partidas ideales (5-3), B salio victoriosa.\nEl codigó de python es el siguiente:\n\n\nVer código\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ncontador = 0\nn = 10_000\ni = 0\n\nwhile i &lt; n:\n\n    separador = np.random.random()\n\n    bolas = np.random.random(8)\n    jugador_A = np.sum(bolas &lt; separador)\n    jugador_B = np.sum(bolas &gt;= separador)\n\n    if jugador_A == 5 and jugador_B == 3:\n        i += 1\n\n        while jugador_A &lt; 6 and jugador_B &lt; 6:\n            bola = np.random.random()\n            if bola &lt; separador:\n                jugador_A += 1\n            else:\n                jugador_B += 1\n\n        if jugador_B == 6:\n            contador += 1\n\nplt.figure(figsize=(8, 4))\nax = plt.gca()\nax.set_facecolor(\"#3a7352\")\ny = np.random.random(8)\nplt.scatter(bolas[bolas &lt; separador], y[:5], color='#2ecc71', s=100, label='Puntos para A')\nplt.scatter(bolas[bolas &gt;= separador], y[5:], color='#e74c3c', s=100, label='Puntos para B')\nplt.axvline(x=separador, color='black', linestyle='--', linewidth=2)\nplt.xlim([0,1])\nplt.ylim([0,1])\nplt.legend()\nplt.title(f\"Partida al inicio del problema (puntos dados al azar)\")\nplt.show()\n\nprint(f\"Numero de partidas: {n}\")\nprint(f\"Numero de veces que gana A: {n-contador}\")\nprint(f\"Numero de veces que gana B: {contador}\")\nprint(f\"Probabilidad de que B gane: {contador/n}\")\n\n\n\n\n\n\n\n\n\nNumero de partidas: 10000\nNumero de veces que gana A: 9098\nNumero de veces que gana B: 902\nProbabilidad de que B gane: 0.0902\n\n\n\n\n\nComo se puede observar, el resultado es el mismo que lo que plantea la estadistica bayesiana (o al menos se acerca mucho), por lo que, una vez la simulacion de montecarlo nos enseña como muchas veces no necesitamos formulas que pueden resultar complicadas o tediosas de entender, sino entender realmente el problema y con un par de lineas de codigo resolver este tipo de incognitas."
  }
]